r'''
UniRef
======

.. currentmodule:: micronota.db.uniref

This module create databases from UniRef for micronota usage. Using UniRef
for functional assignment of coding genes, we can get the clustering of
the annotated proteins for free. Using UniRef100 as the reference database,
we can easily collapse the clusters down to the similarity levels
of 90% or 50%. For those UniRef records from UniProKB, we also transfer
the metadata associated with those UniProKB records.

UniProtKB (UniProt Knowledgebase) [#]_ contains two parts, UniProtKB/Swiss-Prot
and UniProtKB/TrEMBL. The first part contains protein records that are
manually annotated and reviewed while the second part is done computationally
and not manually reviewed.

UniParc (UniProt Archive) [#]_ is also part of UniProt project. It is a
is a comprehensive and non-redundant database that contains most of the
publicly available protein sequences in the world.

The UniProt Reference Clusters (UniRef) [#]_ provide clustered sets (UniRef100,
UniRef90 and UniRef50 clusters) of sequences from the UniProtKB
and selected UniParc records, in order to obtain complete coverage of sequence
space at several resolutions (100%, >90% and >50%) while hiding redundant
sequences (but not their descriptions) from view.

Release
-------
:version: 2016_01
:date:    01/20/2016
:link:    ftp://ftp.uniprot.org/pub/databases/uniprot/relnotes.txt

Files
-----
* UniRef files

  UniRef fasta files clustered at the similarity levels of 50, 90 or 100.
  The UniRef100 identifier is generated by placing "UniRef100_" prefix
  before the UniProtKB accession number or UniParc identifier of the
  representative UniProtKB or UniParc entry. It is similarly done for
  UniRef50 or UniRef90.

  * uniref50.fasta.gz [#]_

  * uniref90.fasta.gz [#]_

  * uniref100.fasta.gz [#]_

* UniProtKB files

  The .dat.gz files contain the UniProtKB records in variant format of EMBL.
  The records are divided into taxa groups [#]_.

  * uniprot_sprot.dat.gz

  * uniprot_trembl.dat.gz

Reference
---------
.. [#] http://www.uniprot.org/help/uniparc
.. [#] http://www.uniprot.org/help/uniprotkb
.. [#] http://www.ncbi.nlm.nih.gov/pubmed/17379688
.. [#] ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/README
.. [#] ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/README
.. [#] ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref100/README
.. [#] ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/taxonomic_divisions/README
'''

# ----------------------------------------------------------------------------
# Copyright (c) 2015--, micronota development team.
#
# Distributed under the terms of the Modified BSD License.
#
# The full license is in the file COPYING.txt, distributed with this software.
# ----------------------------------------------------------------------------

from os.path import join, expanduser
from sqlite3 import connect
import shutil

from skbio import read, Sequence

from ..util import _overwrite


def prepare_db(out_d, prefix='uniref100', force=False,
               server='ftp.uniprot.org',
               path='pub/databases/uniprot/uniref/uniref100',
               fasta='uniref100.fasta.gz'):
    '''Prepare reference database for UniRef.

    Notes
    -----
    This function creates the following files:

    * ``uniref100_sprot_archaea.dmnd``
    * ``uniref100_sprot_bacteria.dmnd``
    * ``uniref100_sprot_viruses.dmnd``
    * ``uniref100_sprot_other.dmnd``
    * ``uniref100_trembl_archaea.dmnd``
    * ``uniref100_trembl_bacteria.dmnd``
    * ``uniref100_trembl_viruses.dmnd``
    * ``uniref100_trembl_other.dmnd``
    * ``uniref100_other.dmnd``

    * ``uniprotkb.db``
    * ``uniref_100_90_50.db``: the map between UniRef100, UniRef90, and UniRef50.
    '''

    prepare_metadata(join(expanduser('~'), 'uniref', 'uniprot_sprot.dat.gz'),
                     '%s.db' % join(out_d, prefix))
    prepare_metadata(join(expanduser('~'), 'uniref', 'uniprot_trembl.dat.gz'),
                     '%s.db' % join(out_d, prefix))
    sort_uniref('%s.db' % join(out_d, prefix), join(expanduser('~'), 'uniref', 'uniref100.fasta.gz'), out_d)

def create_map(fp):
    '''Map between UniRef100, UniRef90, and UniRef50.
    '''


def sort_uniref(db_fp, uniref_fp, out_d):
    '''Sort UniRef sequences into different partitions.'''

    fn = ['%s_%s' % (i, j) for i in ['sprot', 'trembl']
          for j in ['Bacteria', 'Archaea', 'Viruses', 'other']]
    files = {f: open(join(out_d, 'uniref100_%s.fasta' % f), 'w') for f in fn}
    files['_other'] = open('uniref100__other.fasta', 'w')
    with connect(db_fp) as conn:
        cursor = conn.cursor()
        for seq in read(uniref_fp, format='fasta', constructor=Sequence):
            id = seq.metadata['id']
            id = id.replace('UniRef100_', '')
            group = ['', 'other']
            cursor.execute(
                '''SELECT key, val FROM metadata
                   WHERE id = ? AND key IN (?,?)''',
                (id, 'KD', 'RE'))
            for row in cursor.fetchall():
                key, val = row
                if key == 'KD':
                    if val in ['Bacterial', 'Archaea', 'Viruses']:
                        group[1] = val
                if key == 'RE':
                    group[0] = val
            seq.write(files['_'.join(group)])
    conn.commit()
    for f in files:
        files[f].close()


def prepare_metadata(in_fp, fp, overwrite=False):
    '''
    Returns
    -------
    int
        The number of records processed.

    Notes
    -----
    The schema of the database file contains one table named `tigrfam` that
    has following columns:

    1. ``ac``. TEXT. UniProtKB accession.

    2. ``key``. TEXT. 2-letter key.

    3. ``val``. BLOB. The value of the key.

    4. ``transfer``. INTEGER. Used as the boolean. ``1`` means the ``val``
       should be transferred to the query sequences as its annotation;
       ``0`` means not.

    The table in the database file will be dropped and re-created if
    the function is re-run.
    '''
    _overwrite(fp, overwrite)
    with connect(fp) as conn:
        table_name = 'metadata'
        conn.execute('''CREATE TABLE IF NOT EXISTS {t} (
                            ac       TEXT    NOT NULL,
                            key      TEXT    NOT NULL,
                            val      BLOB    NOT NULL,
                            transfer BOOLEAN NOT NULL,
                        CHECK (transfer IN (0,1)));'''.format(t=table_name))

        for n, seq in enumerate(
                read(in_fp, format='embl', constructor=Sequence), 1):
            md = seq.metadata
            ac = md['AC']
            insert = '''INSERT INTO {t} (ac, key, val, transfer)
                        VALUES (?,?,?,?);'''.format(t=table_name)
            conn.execute(insert, (ac, 'OX', md['OX'], 0))
            conn.execute(insert, (ac, 'PE', md['PE'], 0))
            kingdom = md['OC'].split('; ', 1)[0]
            conn.execute(insert, (ac, 'KD', kingdom, 0))
            if md['ID']['quality'] == 'Reviewed':
                group = 'sprot'
            elif md['ID']['quality'] == 'Unreviewed':
                group = 'trembl'
            else:
                raise ValueError('Unrecognized "%s"' % group)
            conn.execute(insert, (ac, 'RE', group, 0))
        # don't forget to index the column to speed up query
        conn.execute('CREATE INDEX IF NOT EXISTS ac ON {t} (ac);'.format(
            t=table_name))
        conn.commit()

    return n
